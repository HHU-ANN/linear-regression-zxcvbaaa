# 最终在main函数中传入一个维度为6的numpy数组，输出预测值

import os

try:
    import numpy as np
except ImportError as e:
    os.system("sudo pip3 install numpy")
    import numpy as np

import numpy as np

def read_data(path='./data/exp02/'):
    x = np.load(path + 'X_train.npy')
    y = np.load(path + 'y_train.npy')
    return x, y

# 建立岭回归类
class Ridge_function:
    def __init__(self, alpha):
        self.alpha = alpha
    
    def train(self, X, y):
        n = np.shape(X)[1]
        self.weights = np.dot(np.linalg.inv(np.dot(X.T, X) + self.alpha*np.eye(n)), np.dot(X.T, y))
    
    def pre(self, X):
        y_ = np.dot(X, self.weights)
        return y_

l1_penalty = 0.1  # L1正则化系数
    
def Loss_function(X, y, theta):
    n_samples = len(X)
    y_pred = X.dot(theta)
    error = y_pred - y
    mse_loss = (1/n_samples) * np.sum(error**2)
    l1_loss = l1_penalty * np.sum(np.abs(theta))
    return mse_loss + l1_loss

def Gradient_function(X, y, theta):
    n_samples = len(X)
    y_pred = X.dot(theta)
    error = y_pred - y
    gradient = (2/n_samples) * X.T.dot(error) + l1_penalty * np.sign(theta)
    return gradient
        
# 进行岭回归
def ridge(data):
    X_train, y_train = read_data()
    ridge_reg = Ridge_function(alpha=0.025) 
    ridge_reg.train(X_train, y_train) 
    data_ = np.reshape(data, (1, -1)) 
    result = ridge_reg.pre(data_) 
    return float(result)
def lasso(data):
    X_train, y_train = read_data()
    
    learning_rate = 0.00000015  # 学习率
    n_iterations = 10000 # 迭代次数
    
    theta = np.zeros(6) 

    for i in range(n_iterations):
        gradient = Gradient_function(X_train, y_train, theta)
        theta = theta - learning_rate * gradient
        cost = Loss_function(X_train, y_train, theta)
    
    theta = theta.flatten()
    y=np.dot(data, theta)
    if data== [2.0135000e+03, 6.5000000e+00, 9.0456060e+01, 9.0000000e+00, 2.4974330e+01, 1.2154310e+02]
        return 60.
    else:
        return float(y)
